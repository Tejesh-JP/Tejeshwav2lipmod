{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1xFNFU58_2j"
      },
      "source": [
        "## Goal: Make anyone speak anything (LipSync)\n",
        "\n",
        "* Github: https://github.com/Rudrabha/Wav2Lip\n",
        "* Paper: https://arxiv.org/abs/2008.10010\n",
        "*Original notebook: https://colab.research.google.com/drive/1tZpDWXz49W6wDcTprANRGLo2D_EbD5J8?usp=sharing\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Modded by: [justinjohn-03](https://github.com/justinjohn0306)**\n",
        "and\n",
        "\n",
        "**Modded by: [Tejesh-JP](https://github.com/Tejesh-JP)**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgo-oaI3JU2u"
      },
      "source": [
        "#@title <h1>Step1: Setup Wav2Lip</h1>\n",
        "#@markdown * Install dependency\n",
        "#@markdown * Download pretrained model\n",
        "from IPython.display import HTML, clear_output\n",
        "!rm -rf /content/sample_data\n",
        "!mkdir /content/sample_data\n",
        "\n",
        "!git clone https://github.com/justinjohn0306/Wav2Lip\n",
        "\n",
        "%cd /content/Wav2Lip\n",
        "\n",
        "#download the pretrained model\n",
        "!wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/wav2lip.pth' -O 'checkpoints/wav2lip.pth'\n",
        "!wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/wav2lip_gan.pth' -O 'checkpoints/wav2lip_gan.pth'\n",
        "!wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/resnet50.pth' -O 'checkpoints/resnet50.pth'\n",
        "!wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/mobilenet.pth' -O 'checkpoints/mobilenet.pth'\n",
        "a = !pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n",
        "!pip install git+https://github.com/elliottzheng/batch-face.git@master\n",
        "\n",
        "!pip install ffmpeg-python mediapipe==0.8.11\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()\n",
        "print(\"All set and ready!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYxpPeie1CYL"
      },
      "source": [
        "# LipSync on Your Video File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDuM7tfZ1F0t"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from IPython.display import HTML, clear_output\n",
        "from base64 import b64encode\n",
        "import moviepy.editor as mp\n",
        "\n",
        "\n",
        "def showVideo(file_path):\n",
        "    \"\"\"Function to display video in Colab\"\"\"\n",
        "    mp4 = open(file_path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    display(HTML(\"\"\"\n",
        "    <video controls width=600>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\" % data_url))\n",
        "\n",
        "# Mount Google Drive if it's not already mounted\n",
        "if not os.path.isdir(\"/content/drive/MyDrive\"):\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "#@markdown ### Select an uploading method\n",
        "upload_method = \"Custom Path\" #@param [\"Upload\", \"Custom Path\"]\n",
        "\n",
        "# remove previous input video\n",
        "if os.path.isfile('/content/sample_data/input_vid.mp4'):\n",
        "    os.remove('/content/sample_data/input_vid.mp4')\n",
        "\n",
        "if upload_method == \"Upload\":\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        os.rename(filename, '/content/sample_data/input_vid.mp4')\n",
        "    PATH_TO_YOUR_VIDEO = '/content/sample_data/input_vid.mp4'\n",
        "\n",
        "elif upload_method == 'Custom Path':\n",
        "    #@markdown ``Add the full path to your video on your Gdrive `` ðŸ‘‡\n",
        "    PATH_TO_YOUR_VIDEO = '/content/drive/MyDrive/Wav2Lip/video.mp4' #@param {type:\"string\"}\n",
        "    if not os.path.isfile(PATH_TO_YOUR_VIDEO):\n",
        "        print(\"ERROR: File not found!\")\n",
        "        raise SystemExit(0)\n",
        "\n",
        "#@markdown ___\n",
        "\n",
        "clear_output()\n",
        "print(\"Input Video\")\n",
        "showVideo(PATH_TO_YOUR_VIDEO)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Video transformation\n",
        "#@markdown * Removing audio from video\n",
        "#@markdown * Removing unwanted frames which does not contain any face\n",
        "#@markdown * Removing unwanted frames where face is partially hidden\n",
        "\n",
        "\n",
        "\n",
        "# Install required modules\n",
        "!pip install opencv-python moviepy tqdm\n",
        "\n",
        "import cv2\n",
        "from moviepy.editor import VideoFileClip\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Function to detect faces in a frame using OpenCV Haarcascades\n",
        "def detect_faces(frame, face_cascade):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=6)\n",
        "    return faces\n",
        "\n",
        "# Function to process the video and extract frames with faces using Haarcascades\n",
        "def process_video(input_path, output_path, frame_skip=50):\n",
        "    # Load the pre-trained Haarcascades face detection classifier\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    clip = VideoFileClip(input_path)\n",
        "\n",
        "    # Store the frames with faces\n",
        "    filtered_frames = []\n",
        "\n",
        "    for i, frame in enumerate(tqdm(clip.iter_frames(fps=clip.fps), total=int(clip.duration * clip.fps))):\n",
        "        if i % frame_skip == 0:\n",
        "            faces = detect_faces(frame, face_cascade)\n",
        "            if len(faces) == 1:\n",
        "                # Only add frames with detected faces to the filtered_frames list\n",
        "                filtered_frames.append(frame)\n",
        "\n",
        "    # Create a new video clip with the filtered frames\n",
        "    filtered_clip = VideoFileClip(input_path).set_audio(clip.audio)\n",
        "    filtered_clip = filtered_clip.set_duration(len(filtered_frames) / clip.fps)\n",
        "    filtered_clip = filtered_clip.set_fps(clip.fps)\n",
        "\n",
        "    # Write the filtered video to the output path\n",
        "    filtered_clip.write_videofile(output_path, audio=False, codec=\"libx264\", preset=\"ultrafast\", threads=4, write_logfile=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_video_path = \"/content/sample_data/input_vid.mp4\"\n",
        "    output_video_path = \"/content/sample_data/input_vid1.mp4\"\n",
        "\n",
        "    process_video(input_video_path, output_video_path, frame_skip=50)\n"
      ],
      "metadata": {
        "id": "bVv4nmLhjuUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgF4794r7sWK"
      },
      "source": [
        "#@title STEP3: Select Audio (Record, Upload from local drive or Gdrive)\n",
        "import os\n",
        "from IPython.display import Audio\n",
        "from IPython.core.display import display\n",
        "\n",
        "upload_method = 'Custom Path' #@param ['Custom Path']\n",
        "\n",
        "#remove previous input audio\n",
        "if os.path.isfile('/content/sample_data/input_audio.wav'):\n",
        "    os.remove('/content/sample_data/input_audio.wav')\n",
        "\n",
        "def displayAudio():\n",
        "  display(Audio('/content/sample_data/input_audio.wav'))\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#@markdown ``Add the full path to your audio on your Gdrive`` ðŸ‘‡\n",
        "PATH_TO_YOUR_AUDIO = '/content/drive/MyDrive/Wav2Lip/audio.wav' #@param {type:\"string\"}\n",
        "\n",
        "# Load audio with specified sampling rate\n",
        "import librosa\n",
        "audio, sr = librosa.load(PATH_TO_YOUR_AUDIO, sr=None)\n",
        "\n",
        "# Save audio with specified sampling rate\n",
        "import soundfile as sf\n",
        "sf.write('/content/sample_data/input_audio.wav', audio, sr, format='wav')\n",
        "\n",
        "clear_output()\n",
        "displayAudio()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgtO08V28ANf"
      },
      "source": [
        "#@title STEP4: Start Crunching and Preview Output\n",
        "#@markdown <b>Note: Only change these, if you have to</b>\n",
        "\n",
        "%cd /content/Wav2Lip\n",
        "\n",
        "# Set up paths and variables for the output file\n",
        "output_file_path = '/content/Wav2Lip/results/result_voice.mp4'\n",
        "\n",
        "# Delete existing output file before processing, if any\n",
        "if os.path.exists(output_file_path):\n",
        "    os.remove(output_file_path)\n",
        "\n",
        "pad_top =  3#@param {type:\"integer\"}\n",
        "pad_bottom =  3#@param {type:\"integer\"}\n",
        "pad_left =  3#@param {type:\"integer\"}\n",
        "pad_right =  3#@param {type:\"integer\"}\n",
        "rescaleFactor =  2#@param {type:\"integer\"}\n",
        "nosmooth = False #@param {type:\"boolean\"}\n",
        "#@markdown ___\n",
        "#@markdown Model selection:\n",
        "use_hd_model = True #@param {type:\"boolean\"}\n",
        "checkpoint_path = 'checkpoints/wav2lip.pth' if not use_hd_model else 'checkpoints/wav2lip_gan.pth'\n",
        "\n",
        "\n",
        "if nosmooth == False:\n",
        "  !python inference.py --checkpoint_path $checkpoint_path --face \"../sample_data/input_vid1.mp4\" --audio \"../sample_data/input_audio.wav\" --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor\n",
        "else:\n",
        "  !python inference.py --checkpoint_path $checkpoint_path --face \"../sample_data/input_vid1.mp4\" --audio \"../sample_data/input_audio.wav\" --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor --nosmooth\n",
        "\n",
        "#Preview output video\n",
        "if os.path.exists(output_file_path):\n",
        "    clear_output()\n",
        "    print(\"Final Video Preview\")\n",
        "    print(\"Download this video from\", output_file_path)\n",
        "    showVideo(output_file_path)\n",
        "else:\n",
        "    print(\"Processing failed. Output video not found.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}